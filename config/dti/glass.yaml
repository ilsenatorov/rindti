# pytorch_lightning==1.7.2
seed_everything: true
trainer:
  logger:
    class_path: pytorch_lightning.loggers.WandbLogger
    init_args:
      log_model: true
      project: pretrain_alphafold
      name: overfit_10
      dir: wandb
  enable_checkpointing: true
  callbacks:
    - class_path: pytorch_lightning.callbacks.StochasticWeightAveraging
      init_args:
        swa_lrs: 1e-2
    - class_path: pytorch_lightning.callbacks.ModelCheckpoint
      init_args:
        monitor: train_loss
        mode: min
    - class_path: pytorch_lightning.callbacks.RichProgressBar
    - class_path: pytorch_lightning.callbacks.RichModelSummary
    - class_path: pytorch_lightning.callbacks.LearningRateMonitor
  gradient_clip_val: 1.0
  accelerator: gpu
  devices: -1
  enable_progress_bar: true
  overfit_batches: 10
  accumulate_grad_batches: null
  log_every_n_steps: 5
  max_epochs: 10000
  precision: 32
  profiler: null
  auto_lr_find: false
  auto_scale_batch_size: false
model:
  merge_features: concat
  optimizer: Adam
  max_lr: 0.0001
  start_lr: 1.0e-05
  min_lr: 1.0e-07
  warmup_epochs: 1
  max_epochs: 10
data:
  filename: datasets/glass/results/prepare_all/pdlnpnclnr_2deeeb4b.pkl
  batch_size: 128
  num_workers: 1
  shuffle: true
  batch_sampling: false
  max_num_nodes: 0
