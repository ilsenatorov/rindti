data: results/prepare_all/random_all_none_class_template_onehot_onehot_onehot_onehot.pkl
# Hardware
batch_size: 64
gpus: 1
max_epochs: 1000
num_workers: 4
profiler: null
seed: 42
# Optimisation + learning
early_stop_patience: 60
gradient_clip_val: 30
lr: 0.0005
momentum: 0.3
monitor: val_loss
optimiser: adamw
reduce_lr_factor: 0.1
reduce_lr_patience: 20
weight_decay: 0.01
weighted: 1
# Model
feat_method: element_l1
mlp_dropout: 0.2
mlp_hidden_dim: 64
model: class
# Drug encoder
drug_dropout: 0.2
drug_hidden_dim: 32
drug_lr: 0.0005 # for drug encoder
drug_node_embed: ginconv
drug_num_heads: 4
drug_num_layers: 3
drug_pool: gmt
drug_pretrain: null
drug_ratio: 0.25
# Prot encoder
prot_dropout: 0.2
prot_hidden_dim: 32
prot_lr: 0.0005 # for protein encoder
prot_node_embed: ginconv
prot_num_heads: 4
prot_num_layers: 3
prot_pool: gmt
prot_pretrain: null
prot_ratio: 0.25
