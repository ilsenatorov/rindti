data: /scratch/SCRATCH_NVME/ilya/pretrain_data/pfam_label_onehotprocessed.pkl
# Hardware
batch_size: 128
gpus: 1
max_epochs: 1000
num_workers: 16
profiler: null
seed: 42
# Optimisation + learning
early_stop_patience: 200
gradient_clip_val: 10
lr: 0.0005
monitor: train_loss
optimiser: adam
reduce_lr_factor: 0.5
reduce_lr_patience: 100
# Model
dropout: 0.2
hidden_dim: 32
model: pfam
prot_per_pfam: 8
margin: 1
batch_per_epoch: 1000
# Encoder
node_embed: ginconv
num_heads: 4
num_layers: 3
pool: gmt
ratio: 0.25
