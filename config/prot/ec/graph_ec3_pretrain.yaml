data: /scratch/SCRATCH_NVME/ilya/pretrain_data/swissprot_ec3_label_none.pkl
# Hardware
batch_size: 128
gpus: 1
max_epochs: 10000
num_workers: 16
profiler: null
seed: 42
# Optimisation + learning
early_stop_patience: 200
gradient_clip_val: 100
lr: 0.001
monitor: train_loss
optimiser: adam
reduce_lr_factor: 0.1
reduce_lr_patience: 100
# Model
dropout: 0.1
hidden_dim: 100
model: class
batch_per_epoch: 1000
prot_per_fam: 16

loss: crossentropy # lifted, crossentropy or snnl
temperature: 0.1
optim_temperature: false
grad_step: 0.1
node_pred: True
frac: 0.1
alpha: 1
# Encoder
pretrain: tb_logs/class/version_1/checkpoints/epoch=299-step=557999.ckpt
node_embed: ginconv
num_heads: 1
num_layers: 3
pool: gmt
ratio: 0.25
