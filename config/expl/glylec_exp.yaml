output_dir: exp/shot2
models:
  - dataset: /scratch/SCRATCH_SAS/roman/rindti/datasets/glylex/ACG/results/prepare_all/rlnwgnranc_7cfb529f.pkl
    drug_method: graph
    prot_method: graph
    models:
      - name: Gly_82_1
        checkpoint: tb_logs/dti_glylec/rlnwgntanc_5e01134f/version_1/version_82/checkpoints/epoch=58-step=152396.ckpt
      - name: Gly_82_2
        checkpoint: tb_logs/dti_glylec/rlnwgntanc_5e01134f/version_1/version_82/checkpoints/epoch=48-step=126566.ckpt
  - dataset: /scratch/SCRATCH_SAS/roman/rindti/datasets/glylex/ACG/results/prepare_all/rlnwlnranc_2cf66a76.pkl
    drug_method: graph
    prot_method: graph
    models:
      - name: Lab_82_1
        checkpoint: tb_logs/dti_glylec/rlnwlntanc_1dc421f8/version_1/version_82/checkpoints/epoch=81-step=211805.ckpt
      - name: Lab_82_2
        checkpoint: tb_logs/dti_glylec/rlnwlntanc_1dc421f8/version_1/version_82/checkpoints/epoch=69-step=180809.ckpt
  - dataset: /scratch/SCRATCH_SAS/roman/rindti/datasets/glylex/ACG/results/prepare_all/rlnwInranc_7fbc4b1d.pkl
    drug_method: sweetnet
    prot_method: graph
    models:
      - name: Swe_82_1
        checkpoint: tb_logs/dti_glylec/rlnwIntanc_4e03bb8f/version_1/version_82/checkpoints/epoch=30-step=80072.ckpt
      - name: Swe_82_2
        checkpoint: tb_logs/dti_glylec/rlnwIntanc_4e03bb8f/version_1/version_82/checkpoints/epoch=20-step=54242.ckpt
methods: [obfuscate, delete]
sequences: /scratch/SCRATCH_SAS/roman/rindti/datasets/glylex/ACG/resources/tables/prot.tsv
datamodule:
  batch_size: 1
model:
  module: class
  feat_method: concat
  monitor: val_loss
  drug:
    hidden_dim: 128
    method: graph
    node:
      module: ginconv
      dropout: 0.1
      hidden_dim: 32
      num_layers: 3
    pool:
      module: gmt
      num_heads: 4
      hidden_dim: 32
      ratio: 0.25
  prot:
    hidden_dim: 128
    method: graph
    node:
      module: ginconv
      dropout: 0.1
      hidden_dim: 64
      num_layers: 3
    pool:
      module: gmt
      num_heads: 4
      hidden_dim: 64
      ratio: 0.25
  mlp:
    dropout: 0.2
    hidden_dim: 512
  optimizer:
    module: adam
    lr: 0.0001
    prot_lr: 0.001
    drug_lr: 0.001
    weight_decay: 0.01
    momentum: 0.01
    reduce_lr:
      factor: 0.1
      patience: 20
      monitor: val_loss
