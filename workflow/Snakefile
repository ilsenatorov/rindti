import os
import os.path as osp
import hashlib
import json
import pandas as pd


configfile: "config/snakemake/default.yaml"


class Namer:
    def __init__(self, cutoff: int = None):
        self.cutoff = cutoff

    def hash_config(self, config: dict) -> str:
        """Hash a config dictionary."""
        as_json = json.dumps(config, sort_keys=True).encode("utf-8")
        return hashlib.md5(as_json).hexdigest()[: self.cutoff]

    def flatten_config(self, config: dict) -> dict:
        """Flatten a config dictionary."""
        return pd.json_normalize(config).T[0].to_dict()

    def get_name(self, config: dict) -> str:
        """Get the name of a config."""
        flat = self.flatten_config(config)
        res = ""
        for k, v in flat.items():
            if k in ["source", "target"]:
                continue
            elif isinstance(v, str):
                res += v[0]
        return res + "_" + self.hash_config(config)

    def __call__(self, config: dict) -> str:
        return self.get_name(config)


class SnakeMakeRule:
    def __init__(self, inp: list = [], out: list = []):
        self.inp = inp
        self.out = out


class SnakemakeHelper:
    def __init__(self, config: dict, namer_cutoff: int = None):
        self.source = config["source"]
        self.config = config
        self.target = "/".join(self.source.split("/")[:-1] + ["results"])
        self.prots = [x.split(".")[0] for x in os.listdir(self.source + "/structures") if x.endswith(".pdb")]
        self.namer = Namer(namer_cutoff)

    def _source(self, *args) -> str:
        return os.path.join(self.source, *args)

    def _target(self, *args) -> str:
        return os.path.join(self.target, *args)

    def create_pymol_scripts(self):
        """Get the pymol scripts."""
        if self.config["prots"]["structures"]["method"] == "whole":
            return SnakeMakeRule([], [])
        else:
            return SnakeMakeRule(
                self._target(
                    "pymol_scripts",
                    self.namer(self.config["prots"]["structures"]),
                    "{prot}.pml",
                ),
                self._target("pymol_scripts"),
            )

    def prot_structures(self):
        if self.config["prots"]["structures"]["method"] == "whole":
            return self._source("structures/{prot}.pdb")
        else:
            return self._target(
                "parsed_structures",
                self.namer(self.config["prots"]["structures"]),
                "{prot}.pdb",
            )


sh = SnakemakeHelper(config, 8)


rinerator_output = f"{target}/rinerator_{config['structures']}/{{protein}}/{{protein}}_h.sif"
rinerator_protein_output = f"{target}/rinerator_based/protein_data_{config['structures']}_{prot_settings}.pkl"

distance_protein_output = f"{target}/distance_based/protein_data_{config['structures']}_{prot_settings}.pkl"
if config["graph"] == "distance":
    protein_output = distance_protein_output
else:
    protein_output = rinerator_protein_output

if config["only_prots"]:  # Only calculate the data for the prots
    output = [protein_output]
    drug_output = ""
    final_output = ""
    transformer_output = ""
    plot_output = ""
else:

    drug_output = target + f"/prepare_drugs/drug_data_{drug_settings}.pkl"

    split_data = (
        "{target}/split_data/{split}_{filtering}_{sampling}_{task}_split.csv".format(
            target=target,
            split=config["split"]["method"],
            filtering=config["parse_dataset"]["filtering"],
            sampling=config["parse_dataset"]["sampling"],
            task=config["parse_dataset"]["task"],
        )
        if not config["only_prots"]
        else ""
    )

    transformer_output = "{target}/prepare_transformer/{node_feats}_transformer.pkl".format(
        target=target, node_feats=config["prepare_prots"]["node_feats"]
    )

    final_output = "{target}/prepare_all/{split}_{filtering}_{sampling}_{task}_{structures}_{graph}_{prot_settings}_{drug_settings}.pkl".format(
        target=target,
        split=config["split"]["method"],
        filtering=config["parse_dataset"]["filtering"],
        sampling=config["parse_dataset"]["sampling"],
        task=config["parse_dataset"]["task"],
        structures=config["structures"],
        graph=config["graph"],
        prot_settings=prot_settings,
        drug_settings=drug_settings,
    )

    plot_output = final_output.split("/")[-1].split(".")[0]
    plot_output = f"{target}/report/plot_summary/{plot_output}.html"

    output = [final_output, plot_output]

### CHECK IF FILES ARE PRESENT ###

### CHECK IF templates ARE PRESENT ###
if osp.isdir(os.path.join(source, "templates")):
    templates = expand(
        "{resources}/templates/{template}", resources=source, template=os.listdir(f"{source}/templates")
    )
else:
    if not config["only_prots"] and config["structures"] not in ["whole", "plddt"]:
        raise ValueError("No templates available")
    templates = []

### CHECK IF gnomad is available ###
if osp.isfile(os.path.join(source, "gnomad.csv")):
    gnomad = source + "/gnomad.csv"
    output.append(transformer_output)
else:
    gnomad = []

### CHECK IF drug data is available ###

if osp.isdir(os.path.join(source, "drugs")):
    drugs = {x: source + "/drugs/{x}.tsv".format(x=x) for x in ["inter", "lig", "prots"]}
else:
    if not config["only_prots"]:
        raise ValueError("No drug interaction data available, can't calculate final data!")
    drugs = {x: [] for x in ["inter", "lig"]}


rule all:
    input:
        output,


rule create_pymol_scripts:
    input:
        expand(sh.pymol_scripts(), prot=sh.targets),
    output:
        scripts=expand(script_output, protein=targets),
    log:
        expand("{results}/logs/pymol_bsite.log", results=target),
    message:
        "Creating bsite PyMOL scripts for all protein, logs are in {log}"
    script:
        "scripts/create_pymol_scripts.py"


rule run_pymol:
    input:
        script=script_output,
        struct=source + "/structures/{protein}.pdb",
    output:
        structures=structures,
    log:
        target + "/logs/run_pymol/{protein}.log",
    conda:
        "envs/pymol.yaml"
    message:
        "Running PyMOL script for {wildcards.protein}, logs are in {log}"
    shell:
        """
        pymol -k -y -c {input.script} > {log} 2>&1
        """


rule save_structure_info:
    input:
        structs=expand(structures, protein=targets),
    output:
        tsv="{results}/structure_info/{type}_info.tsv".format(results=target, type=config["structures"]),
    script:
        "scripts/save_structure_info.py"


rule rinerator:
    input:
        pdb=structures,
    output:
        sif=rinerator_output,
    log:
        target + "/logs/rinerator/{protein}.log",
    params:
        dir="{results}/rinerator_{structures}".format(results=target, structures=config["structures"]),
    message:
        "Running RINerator for {wildcards.protein}, logs are in {log}"
    shadow:
        "shallow"
    shell:
        """
        rinerator {input.pdb} {params.dir}/{wildcards.protein} > {log} 2>&1
        """


rule distance_based:
    input:
        pdbs=expand(structures, protein=targets),
    output:
        pickle=distance_protein_output,
    log:
        expand("{results}/logs/distance_based.log", results=target),
    params:
        threshold=config["distance"]["threshold"],
    message:
        "Running distance based network calculation, logs are in {log}"
    script:
        "scripts/distance_based.py"


rule prepare_prots:
    input:
        rins=expand(rinerator_output, protein=targets),
    output:
        protein_pickle=rinerator_protein_output,
    message:
        """
        Creating protein data.
        Structures config is {config[structures]}
        Node feature type is {config[prepare_prots][node_feats]}.
        Edge feature type is {config[prepare_prots][edge_feats]}.
        """
    script:
        "scripts/prepare_prots.py"


rule parse_dataset:
    input:
        inter=drugs["inter"],
    output:
        inter="{results}/parse_dataset/{filtering}_{sampling}_inter.csv".format(
            results=target,
            filtering=config["parse_dataset"]["filtering"] if not config["only_prots"] else "",
            sampling=config["parse_dataset"]["sampling"] if not config["only_prots"] else "",
        ),
    message:
        """Parsing the dataset

        Filtering is {config[parse_dataset][filtering]}
        Sampling is {config[parse_dataset][sampling]}
        Task is {config[parse_dataset][task]}
        Log is {config[parse_dataset][log]}
        Threshold is {config[parse_dataset][threshold]}
        """
    script:
        "scripts/parse_dataset.py"


rule split_data:
    input:
        inter=rules.parse_dataset.output.inter,
    output:
        split_data="{results}/split_data/{split}_{filtering}_{sampling}_split.csv".format(
            results=target,
            split=config["split"]["method"] if not config["only_prots"] else "",
            filtering=config["parse_dataset"]["filtering"] if not config["only_prots"] else "",
            sampling=config["parse_dataset"]["sampling"] if not config["only_prots"] else "",
        ),
    message:
        "Splitting the dataset with {config[split][method]} method"
    script:
        "scripts/split_data.py"


rule prepare_drugs:
    input:
        lig=drugs["lig"],
    output:
        drug_pickle=drug_output,
    message:
        "Encoding the drugs"
    script:
        "scripts/prepare_drugs.py"


rule prepare_all:
    input:
        drugs=rules.prepare_drugs.output.drug_pickle,
        prots=protein_output,
        inter=rules.split_data.output.split_data,
        protseqs=drugs["prots"],
    output:
        combined_pickle=final_output,
    message:
        """
        Combining the final dataset.
        """
    script:
        "scripts/prepare_all.py"


rule prepare_transformer:
    input:
        gnomad=gnomad,
        prots=rules.prepare_prots.output.protein_pickle,
    output:
        transformer_pickle=transformer_output,
    script:
        "scripts/prepare_transformer.py"


rule plot_summary:
    input:
        pickle=rules.prepare_all.output.combined_pickle,
        struct_info=rules.save_structure_info.output.tsv,
    output:
        html=plot_output,
    script:
        "scripts/plot_summary.py"
